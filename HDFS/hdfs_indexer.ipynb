{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d663b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch\n",
      "{'cluster_name': 'docker-cluster',\n",
      " 'cluster_uuid': '4Xf3-_8JQxCX6HVz9r0yvA',\n",
      " 'name': '5a0a9ef6b26a',\n",
      " 'tagline': 'You Know, for Search',\n",
      " 'version': {'build_date': '2024-08-05T10:05:34.233336849Z',\n",
      "             'build_flavor': 'default',\n",
      "             'build_hash': '1a77947f34deddb41af25e6f0ddb8e830159c179',\n",
      "             'build_snapshot': False,\n",
      "             'build_type': 'docker',\n",
      "             'lucene_version': '9.11.1',\n",
      "             'minimum_index_compatibility_version': '7.0.0',\n",
      "             'minimum_wire_compatibility_version': '7.17.0',\n",
      "             'number': '8.15.0'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from elasticsearch  import Elasticsearch, helpers\n",
    "import json\n",
    "\n",
    "#Connect to elasticsearch\n",
    "es = Elasticsearch('http://localhost:9200')\n",
    "client_info = es.info()\n",
    "print(\"Connected to Elasticsearch\")\n",
    "pprint(client_info.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e689a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created: hdfs\n"
     ]
    }
   ],
   "source": [
    "# Delete old index if it exists\n",
    "es.indices.delete(index='hdfs', ignore_unavailable=True)\n",
    "\n",
    "# Create HDFS index\n",
    "es.indices.create(\n",
    "    index=\"hdfs\",\n",
    "    settings={\n",
    "        \"index\": {\n",
    "            \"number_of_shards\": 3,\n",
    "            \"number_of_replicas\": 2\n",
    "        }\n",
    "    },\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            # Parsed / normalized timestamps (you'll populate these when ingesting)\n",
    "            \"timestamp_iso\": {\n",
    "                \"type\": \"date\",\n",
    "                \"format\": \"strict_date_time||yyyy-MM-dd HH:mm:ss||yyyy-MM-dd HH:mm:ss.SSS\"\n",
    "            },\n",
    "            \"timestamp_epoch\": {\"type\": \"long\"},\n",
    "\n",
    "            # Raw date/time fragments from the HDFS log line\n",
    "            # Example: \"081109 203615 148 INFO dfs.DataNode$PacketResponder: ...\"\n",
    "            \"date_raw\":   {\"type\": \"keyword\"},   # e.g. \"081109\"\n",
    "            \"time_raw\":   {\"type\": \"keyword\"},   # e.g. \"203615\"\n",
    "            \"millis\":     {\"type\": \"integer\"},   # e.g. 148\n",
    "\n",
    "            # Log meta info\n",
    "            \"log_level\":  {\"type\": \"keyword\"},   # INFO / WARN / ERROR ...\n",
    "            \"component\":  {\"type\": \"keyword\"},   # e.g. \"dfs.DataNode$PacketResponder\"\n",
    "\n",
    "            # Message & full line\n",
    "            \"message\":    {\"type\": \"text\"},      # e.g. \"PacketResponder 1 for block blk_... terminating\"\n",
    "            \"raw_line\":   {\"type\": \"text\"},      # full unparsed log line\n",
    "\n",
    "            # Optional: where the log came from\n",
    "            \"source_path\": {\"type\": \"keyword\"}   # e.g. \"C:\\\\Users\\\\nikhi\\\\loghub\\\\HDFS\\\\HDFS_2k.log\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Index created: hdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c080b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulk upload completed for HDFS!\n"
     ]
    }
   ],
   "source": [
    "# Bulk import NDJSON for the hdfs index\n",
    "import json\n",
    "from elasticsearch import helpers\n",
    "\n",
    "NDJSON_FILE = r\"C:\\Users\\nikhi\\loghub\\HDFS\\hdfs_bulk.ndjson\"\n",
    "\n",
    "def generate_actions():\n",
    "    with open(NDJSON_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        # NDJSON follows the same pattern:\n",
    "        # { \"index\": {} }\n",
    "        # { actual_document }\n",
    "        for i in range(0, len(lines), 2):\n",
    "            _ = json.loads(lines[i])            # index meta (not used)\n",
    "            doc = json.loads(lines[i + 1])      # actual HDFS log document\n",
    "\n",
    "            yield {\n",
    "                \"_index\": \"hdfs\",\n",
    "                \"_source\": doc\n",
    "            }\n",
    "\n",
    "helpers.bulk(es, generate_actions())\n",
    "\n",
    "print(\"Bulk upload completed for HDFS!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0290f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 136, 'timed_out': False, '_shards': {'total': 3, 'successful': 3, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 2000, 'relation': 'eq'}, 'max_score': 1.0, 'hits': [{'_index': 'hdfs', '_id': '0U5jgZoBd5gvbmloCY5C', '_score': 1.0, '_source': {'timestamp_epoch': 1226243287, 'timestamp_iso': '2008-11-09T20:38:07.222000Z', 'date_raw': '081109', 'time_raw': '203807', 'millis': '222', 'level': 'INFO', 'component': 'dfs.DataNode$PacketResponder', 'message': 'PacketResponder 0 for block blk_-6952295868487656571 terminating', 'raw_line': '081109 203807 222 INFO dfs.DataNode$PacketResponder: PacketResponder 0 for block blk_-6952295868487656571 terminating'}}, {'_index': 'hdfs', '_id': '0k5jgZoBd5gvbmloCY5C', '_score': 1.0, '_source': {'timestamp_epoch': 1226243405, 'timestamp_iso': '2008-11-09T20:40:05.035000Z', 'date_raw': '081109', 'time_raw': '204005', 'millis': '35', 'level': 'INFO', 'component': 'dfs.FSNamesystem', 'message': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.73.220:50010 is added to blk_7128370237687728475 size 67108864', 'raw_line': '081109 204005 35 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.73.220:50010 is added to blk_7128370237687728475 size 67108864'}}, {'_index': 'hdfs', '_id': '005jgZoBd5gvbmloCY5C', '_score': 1.0, '_source': {'timestamp_epoch': 1226243415, 'timestamp_iso': '2008-11-09T20:40:15.308000Z', 'date_raw': '081109', 'time_raw': '204015', 'millis': '308', 'level': 'INFO', 'component': 'dfs.DataNode$PacketResponder', 'message': 'PacketResponder 2 for block blk_8229193803249955061 terminating', 'raw_line': '081109 204015 308 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_8229193803249955061 terminating'}}, {'_index': 'hdfs', '_id': '2E5jgZoBd5gvbmloCY5D', '_score': 1.0, '_source': {'timestamp_epoch': 1226243725, 'timestamp_iso': '2008-11-09T20:45:25.512000Z', 'date_raw': '081109', 'time_raw': '204525', 'millis': '512', 'level': 'INFO', 'component': 'dfs.DataNode$PacketResponder', 'message': 'PacketResponder 2 for block blk_572492839287299681 terminating', 'raw_line': '081109 204525 512 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_572492839287299681 terminating'}}, {'_index': 'hdfs', '_id': '2U5jgZoBd5gvbmloCY5D', '_score': 1.0, '_source': {'timestamp_epoch': 1226243815, 'timestamp_iso': '2008-11-09T20:46:55.556000Z', 'date_raw': '081109', 'time_raw': '204655', 'millis': '556', 'level': 'INFO', 'component': 'dfs.DataNode$PacketResponder', 'message': 'Received block blk_3587508140051953248 of size 67108864 from /10.251.42.84', 'raw_line': '081109 204655 556 INFO dfs.DataNode$PacketResponder: Received block blk_3587508140051953248 of size 67108864 from /10.251.42.84'}}, {'_index': 'hdfs', '_id': '2k5jgZoBd5gvbmloCY5D', '_score': 1.0, '_source': {'timestamp_epoch': 1226243842, 'timestamp_iso': '2008-11-09T20:47:22.567000Z', 'date_raw': '081109', 'time_raw': '204722', 'millis': '567', 'level': 'INFO', 'component': 'dfs.DataNode$PacketResponder', 'message': 'Received block blk_5402003568334525940 of size 67108864 from /10.251.214.112', 'raw_line': '081109 204722 567 INFO dfs.DataNode$PacketResponder: Received block blk_5402003568334525940 of size 67108864 from /10.251.214.112'}}, {'_index': 'hdfs', '_id': '3U5jgZoBd5gvbmloCY5D', '_score': 1.0, '_source': {'timestamp_epoch': 1226243948, 'timestamp_iso': '2008-11-09T20:49:08.031000Z', 'date_raw': '081109', 'time_raw': '204908', 'millis': '31', 'level': 'INFO', 'component': 'dfs.FSNamesystem', 'message': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.110.8:50010 is added to blk_8015913224713045110 size 67108864', 'raw_line': '081109 204908 31 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.110.8:50010 is added to blk_8015913224713045110 size 67108864'}}, {'_index': 'hdfs', '_id': '3k5jgZoBd5gvbmloCY5D', '_score': 1.0, '_source': {'timestamp_epoch': 1226243965, 'timestamp_iso': '2008-11-09T20:49:25.673000Z', 'date_raw': '081109', 'time_raw': '204925', 'millis': '673', 'level': 'INFO', 'component': 'dfs.DataNode$DataXceiver', 'message': 'Receiving block blk_-5623176793330377570 src: /10.251.75.228:53725 dest: /10.251.75.228:50010', 'raw_line': '081109 204925 673 INFO dfs.DataNode$DataXceiver: Receiving block blk_-5623176793330377570 src: /10.251.75.228:53725 dest: /10.251.75.228:50010'}}, {'_index': 'hdfs', '_id': '4E5jgZoBd5gvbmloCY5D', '_score': 1.0, '_source': {'timestamp_epoch': 1226244056, 'timestamp_iso': '2008-11-09T20:50:56.710000Z', 'date_raw': '081109', 'time_raw': '205056', 'millis': '710', 'level': 'INFO', 'component': 'dfs.DataNode$PacketResponder', 'message': 'PacketResponder 1 for block blk_5017373558217225674 terminating', 'raw_line': '081109 205056 710 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_5017373558217225674 terminating'}}, {'_index': 'hdfs', '_id': '4U5jgZoBd5gvbmloCY5D', '_score': 1.0, '_source': {'timestamp_epoch': 1226244117, 'timestamp_iso': '2008-11-09T20:51:57.752000Z', 'date_raw': '081109', 'time_raw': '205157', 'millis': '752', 'level': 'INFO', 'component': 'dfs.DataNode$PacketResponder', 'message': 'Received block blk_9212264480425680329 of size 67108864 from /10.251.123.1', 'raw_line': '081109 205157 752 INFO dfs.DataNode$PacketResponder: Received block blk_9212264480425680329 of size 67108864 from /10.251.123.1'}}]}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = es.search(\n",
    "    index=\"hdfs\",\n",
    "    query={\"match_all\": {}},\n",
    "    size=10\n",
    ")\n",
    "\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "841c3ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 4, 'timed_out': False, '_shards': {'total': 3, 'successful': 3, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 0, 'relation': 'eq'}, 'max_score': None, 'hits': []}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = es.search(\n",
    "    index=\"hdfs\",\n",
    "    query={\n",
    "        \"term\": {\n",
    "            \"log_level\": \"INFO\"\n",
    "        }\n",
    "    },\n",
    "    size=10\n",
    ")\n",
    "\n",
    "resp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd903163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
